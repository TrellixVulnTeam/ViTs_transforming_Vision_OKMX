# Finetuning and Evaluating Vision Transformers and ResNets for Image Classification
(Validating image classification benchmark results on ViTs, DeiT and ResNets BiT models)

Hello everyone!
This repository contains the code implementation for our ML701 project "Transformers Transforming Vision", in which we have revisted the baseline vision transformers such as ViTs, DeiT and compared them with the CNN models like ResNet BiT.

We have tried to validate the official published results of ViTs, DeiTs and ResNets on CIFAR-10 and CIFAR-100, when they are pretrained on different datasets like ImageNet and ImageNet-21k. Additionally, we have used CUB200 dataset and exploited the importance of having high resolution images specifically for vision transformers. Our approch is summarized below:

Specifically, we provided finetuning and evalutation scripts for all ResNet-BiT, ViT and DeiT models which are supported by PyTorch library.



-----------

Requirements
---


------------

Finetuning models
---


------------



Evaluating model
---



------------
